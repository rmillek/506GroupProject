---
title: "506 Project SAS Section"
author: "Group 11"
output: html_document
---

### Import data to SAS:

```{}
/* file name */
filename seeds '~/stat506/project/seeds_dataset.txt';

/* import data */
data seeds_original;
	infile seeds delimiter = '	' MISSOVER;
	input area peri comp l w asym igroove group;
run;
```

$~$

### Train/Test

- Using "train and test split" with ratio 7:3 to create training and testing datasets:

```{}
/* train and test split by group */
proc surveyselect data=seeds_original rate=.3 outall out=seeds_select;
	strata group;
run;

/* training set*/
data seeds_train;
	set seeds_select;
	where Selected = 0;
	drop Selected SelectionProb SamplingWeight;
run;

/* testing set*/
data seeds_test;
	set seeds_select;
	where Selected = 1;
	drop Selected SelectionProb SamplingWeight;
run;
```

$~$

### Summary of training dataset:

```{}
/* summary of training dataset*/
proc means data=seeds_train n mean std min max;
  var area peri comp l w asym igroove;
run;
```


```{r echo=FALSE, out.width = '60%', fig.align='center'}
knitr::include_graphics("train_sum.png")
```

There are 147 observations in the training dataset.

$~$

### Summary of training dataset by group:

```{}
/* summary of training dataset by group*/
proc means data=seeds_train n mean std;
  class group;
  var area peri comp l w asym igroove;
run;
```

Group 1 is Kama; Group 2 is Rose; Group 3 is Canadian. The table below shows the mean of each predictors by different groups. Several variables have clear differences of means for different groups.


```{r echo=FALSE, out.width = '40%', fig.align='center'}
knitr::include_graphics("train_sum_group.png")
```

$~$

### Correlation between predictors:

```{}
/* correlation */
proc corr data=seeds_train;
  var area peri comp l w asym igroove;
run;
```

```{r echo=FALSE, out.width = '50%', fig.align='center'}
knitr::include_graphics("cor.png")
```

$~$

### Discriminant Analysis (using "discrim" function):

```{}
/* analysis */
proc discrim data=seeds_train testdata=seeds_test testout=fake_out out=discrim_out can;
  class group;
  var area peri comp l w asym igroove;
run;
```

```{r echo=FALSE, out.width = '100%', fig.align='center'}
knitr::include_graphics("a_1.png")
```

There are three groups which indicates that the number of discriminant dimensions is 3-1 which is 2. The two discriminant dimensions are both statistically significant based on the table above (P values of the F-tests are very small). As a result, both dimensions are very useful to describe the differences between the groups of seeds. The canonical correlations for the two dimensions are 0.93 and 0.87.


$~$

The four tables below provide us more details of the model that we get based on the training dataset. We can know the discriminat coefficients (raw and standardized) and class means of each demension.

```{r echo=FALSE, out.width = '40%', fig.align='center'}
knitr::include_graphics("a_7.png")
```

```{r echo=FALSE, out.width = '30%', fig.align='center'}
knitr::include_graphics("a_8.png")
```

```{r echo=FALSE, out.width = '30%', fig.align='center'}
knitr::include_graphics("a_9.png")
```

```{r echo=FALSE, out.width = '35%', fig.align='center'}
knitr::include_graphics("a_10.png")
```

The two discrimant functions are (based on the standardized coefficients):

$discriminant_1 = -0.301*Area + 0.379*Perimeter + ... + 0.821*Groove$

$discriminant_2 = 4.103*Area + -4.631*Perimeter + ... + 1.694*Groove$

$~$

The two tables below are the summary tables of training and tesing dataset. Based on these two tables, we can notice that the training error and testing error are both very small. The accuracy is almost 1. The model predicts the data well.

```{r echo=FALSE, out.width = '40%', fig.align='center'}
knitr::include_graphics("a_5.png")
```

```{r echo=FALSE, out.width = '40%', fig.align='center'}
knitr::include_graphics("a_4.png")
```

$~$

### Plot the classification:

```{}
/* plot */
data plotclass;
  merge fake_out discrim_out;
run;

proc template;
  define statgraph classify;
    begingraph;
      layout overlay;
        contourplotparm x=Can1 y=Can2 z=_into_ / contourtype=fill  
						 nhint = 30 gridded = false;
        scatterplot x=Can1 y=Can2 / group=group includemissinggroup=false
	                 	    markercharactergroup = group;
      endlayout;
    endgraph;
  end;
run;

proc sgrender data = plotclass template = classify;
run;
```

```{r echo=FALSE, out.width = '70%', fig.align='center'}
knitr::include_graphics("plot_da.png")
```

From the plot, we can know that two discriminant dimensions can classify groups very well. We can notice that "can1" can seperate group 2 from other two groups and "can2" can seperate group 1 and group 3 well.



